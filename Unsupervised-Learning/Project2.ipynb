{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import radius_neighbors_graph, NearestNeighbors\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/avsngh/Mathematical Statistics/Masters-Projects/Unsupervised-Learning/Data/Star_Data.txt'\n",
    "data = pd.read_csv(filepath_or_buffer=data_path, sep='\\s+', header=None)\n",
    "data.columns = ['col1','col2']\n",
    "data_df=pd.DataFrame.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(data_df['col1'], data_df['col2'], marker='o', alpha=0.7)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Distribution of Star Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Creating Îµ neighbourhood graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 3\n",
    "sim_matrix = radius_neighbors_graph(X=data_df, radius= epsilon, mode='distance', metric='euclidean', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using networkx library we create a graph which we will visualize in the next step\n",
    "nx_graph = nx.from_scipy_sparse_array(sim_matrix)\n",
    "coordinates_dict={}\n",
    "coordinates_dict = {i: [data_df.at[i, 'col1'], data_df.at[i, 'col2']] for i in range(len(data))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw_networkx(G=nx_graph,pos=coordinates_dict, with_labels= False, node_size = 10, node_color= '#C70039', alpha = 0.7, width =0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function which calculates a symmetric adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_weighted_adjacency_matrix(data, k=5, similarity='gaussian', sigma=1.0, epsilon=1e-5, custom_similarity_func=None):\n",
    "    \"\"\"\n",
    "    Creates a weighted adjacency matrix from data using a specified or custom similarity function.\n",
    "\n",
    "    \"\"\"\n",
    "    N = data.shape[0]\n",
    "    \n",
    "    # Determine the appropriate metric and preprocessing based on the similarity function\n",
    "    if similarity == 'cosine':\n",
    "        metric = 'cosine'\n",
    "        # Normalize data for cosine similarity\n",
    "        from sklearn.preprocessing import normalize\n",
    "        data_normalized = normalize(data)\n",
    "        data_to_use = data_normalized\n",
    "    else:\n",
    "        metric = 'euclidean'\n",
    "        data_to_use = data\n",
    "\n",
    "    # Compute the nearest neighbors\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto', metric=metric).fit(data_to_use)\n",
    "    distances, indices = nbrs.kneighbors(data_to_use)\n",
    "\n",
    "    # Initialize the weighted adjacency matrix\n",
    "    W = np.zeros((N, N))\n",
    "\n",
    "    # Define default similarity functions\n",
    "    def gaussian_similarity(distance):\n",
    "        return np.exp(- (distance ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "    def inverse_distance_similarity(distance):\n",
    "        return 1.0 / (distance + epsilon)\n",
    "\n",
    "    def cosine_similarity(cosine_distance):\n",
    "        return 1.0 - cosine_distance\n",
    "\n",
    "    # Choose the similarity function\n",
    "    if similarity == 'gaussian':\n",
    "        sim_func = gaussian_similarity\n",
    "    elif similarity == 'inverse_distance':\n",
    "        sim_func = inverse_distance_similarity\n",
    "    elif similarity == 'cosine':\n",
    "        sim_func = cosine_similarity\n",
    "    elif similarity == 'custom':\n",
    "        if custom_similarity_func is not None:\n",
    "            sim_func = custom_similarity_func\n",
    "        else:\n",
    "            raise ValueError(\"Custom similarity function must be provided when similarity='custom'.\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid similarity function. Choose 'gaussian', 'inverse_distance', 'cosine', or 'custom'.\")\n",
    "\n",
    "    # Populate the weighted adjacency matrix\n",
    "    for i in range(N):\n",
    "        for idx, j in enumerate(indices[i]):\n",
    "            if i != j:  # Exclude self-loops\n",
    "                distance = distances[i][idx]\n",
    "                weight = sim_func(distance)\n",
    "                W[i][j] = weight\n",
    "                W[j][i] = weight  # For undirected graph\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_knn = create_weighted_adjacency_matrix(data=np.array(data), k=12, sigma= 0.7)\n",
    "sim_matrix_knn = csr_matrix(sim_matrix_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nx_graph_knn = nx.from_scipy_sparse_array(sim_matrix_knn)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw_networkx(G=nx_graph_knn,pos=coordinates_dict, with_labels= False, node_size = 10, node_color= '#C70039', alpha = 0.7, width =0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_symmetric(csr_matrix):\n",
    "    return (csr_matrix != csr_matrix.transpose()).nnz == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_symmetric(sim_matrix_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for Degree matrix and Eigenspace calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_degree_matrix(csr_weight_matrix):\n",
    "    number_of_vertices = csr_weight_matrix.get_shape()[0]\n",
    "    degree_sums = []\n",
    "    for i in range(number_of_vertices):\n",
    "        degree = scipy.sparse.csr_matrix.sum(csr_weight_matrix.getrow(i))\n",
    "        degree_sums.append(degree)\n",
    "    degree_matrix = np.diag(degree_sums)\n",
    "    return degree_matrix\n",
    "\n",
    "def eigenspace_calculation(matrix, k: int = 1):\n",
    "    np.random.seed(42)\n",
    "    v0 = np.random.rand(matrix.shape[0])\n",
    "    eigenvals,eigenvects = scipy.sparse.linalg.eigs(matrix, k=k, which='SM', v0=v0, maxiter=20000)\n",
    "    return eigenvals, eigenvects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_matrix = create_degree_matrix(sim_matrix_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm_laplacian_matrix=degree_matrix-sim_matrix_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvals,eigenvects = eigenspace_calculation(matrix=unnorm_laplacian_matrix, k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_1=eigenvects[:,1]\n",
    "eigenvector_2=eigenvects[:,2]\n",
    "two_eig_df = pd.DataFrame(np.column_stack((eigenvector_1, eigenvector_2)), columns=['eigenvect1', 'eigenvect2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = list(range(len(eigenvals)))\n",
    "\n",
    "# Scatter plot of the data\n",
    "plt.scatter(x_values, eigenvals)\n",
    "\n",
    "plt.title('Plot of Eigenvalues')\n",
    "plt.xlabel('Eigenvalue')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-12\n",
    "\n",
    "# Count eigenvalues close to zero\n",
    "zero_eigenvalues = np.sum(np.abs(eigenvals) < epsilon)\n",
    "print(f\"Number of zero eigenvalues: {zero_eigenvalues}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(two_eig_df['eigenvect1'], two_eig_df['eigenvect2'], marker='o', alpha=0.9, c=two_eig_df['eigenvect1'], cmap='RdYlBu', s=10)\n",
    "plt.xlabel('Eigenvector 2')\n",
    "plt.ylabel('Eigenvector 3')\n",
    "plt.title('Distribution of y(i)s after Unnormalized Laplacian transformation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_eig_df['eigenvect1'] = two_eig_df['eigenvect1'].apply(lambda val: val.real)\n",
    "two_eig_df['eigenvect2']= two_eig_df['eigenvect2'].apply(lambda val: val.real)\n",
    "\n",
    "k = 2  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "two_eig_df['cluster'] = kmeans.fit_predict(two_eig_df[['eigenvect1', 'eigenvect2']])\n",
    "\n",
    "colors = two_eig_df['cluster'].array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(data_df['col1'], data_df['col2'], marker='o', alpha=0.7, c=colors, cmap='RdYlBu', s=10 )\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Clusters using K-means clustering after Unnormalized Laplacian Transformation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_inv_sqrt = np.diag(1.0 / np.sqrt(np.diag(degree_matrix)))\n",
    "\n",
    "# Calculate D^(-1/2) * L * D^(-1/2)\n",
    "normalized_L = D_inv_sqrt @ unnorm_laplacian_matrix @ D_inv_sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_eigenvals, norm_eigenvects = eigenspace_calculation(matrix=normalized_L, k=3)\n",
    "norm_eigenvector_1=norm_eigenvects[:,1]\n",
    "norm_eigenvector_2=norm_eigenvects[:,2]\n",
    "norm_two_eig_df = pd.DataFrame(np.column_stack((norm_eigenvector_1, norm_eigenvector_2)), columns=['eigenvect1', 'eigenvect2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(norm_two_eig_df['eigenvect1'], norm_two_eig_df['eigenvect2'], marker='o', alpha=0.9, c=two_eig_df['eigenvect1'], cmap='RdYlBu', s=10)\n",
    "plt.xlabel('Eigenvector 2')\n",
    "plt.ylabel('Eigenvector 3')\n",
    "plt.title('Distribution after spectral clustering using Normalized Laplacian Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_two_eig_df['eigenvect1'] = norm_two_eig_df['eigenvect1'].apply(lambda val: val.real)\n",
    "norm_two_eig_df['eigenvect2']= norm_two_eig_df['eigenvect2'].apply(lambda val: val.real)\n",
    "\n",
    "k = 2  # Number of clusters, you can adjust this value\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "norm_two_eig_df['cluster'] = kmeans.fit_predict(norm_two_eig_df[['eigenvect1', 'eigenvect2']])\n",
    "\n",
    "norm_colors = norm_two_eig_df['cluster'].array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(data_df['col1'], data_df['col2'], marker='o', alpha=0.9, c=norm_colors, cmap='RdYlBu', s=10)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Clusters using K-means clustering after Normalized Laplacian Transformation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Manifold Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/avsngh/Mathematical Statistics/Masters-Projects/Unsupervised-Learning/Data/Swiss_Roll.txt'\n",
    "swiss_roll_data = pd.read_csv(filepath_or_buffer=data_path, sep='\\s+', header=None)\n",
    "swiss_roll_data.columns = ['col1','col2', 'col3']\n",
    "swiss_roll_data_df=pd.DataFrame.from_dict(swiss_roll_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data in 3-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = swiss_roll_data_df['col1']+swiss_roll_data_df['col3']\n",
    "trace = go.Scatter3d(x=swiss_roll_data_df['col1'], y=swiss_roll_data_df['col2'], z=swiss_roll_data_df['col3'], \n",
    "                     mode='markers', marker=dict(size=3, color=colors, colorscale='viridis', opacity=0.8))\n",
    "layout = go.Layout(title='3D Scatter Plot', margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "# Showing the plot\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "pyo.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating similartity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_knn_2 = create_weighted_adjacency_matrix(data=np.array(swiss_roll_data_df), k=5, sigma=5)\n",
    "sim_matrix_knn_2 = csr_matrix(sim_matrix_knn_2)\n",
    "degree_matrix_2 = create_degree_matrix(sim_matrix_knn_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing eigenvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm_laplacian_matrix_2=degree_matrix_2-sim_matrix_knn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvals,eigenvects = eigenspace_calculation(matrix=unnorm_laplacian_matrix_2, k=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_1=eigenvects[:,1]\n",
    "eigenvector_2=eigenvects[:,2]\n",
    "two_eig_df_2 = pd.DataFrame(np.column_stack((eigenvector_1, eigenvector_2)), columns=['eigenvect1', 'eigenvect2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x=two_eig_df_2['eigenvect1'], y=two_eig_df_2['eigenvect2'], marker='o', alpha=0.9, c=two_eig_df_2['eigenvect1'], cmap='viridis',s=10)\n",
    "plt.xlabel('Eigenvector 2')\n",
    "plt.ylabel('Eigenvector 3')\n",
    "plt.title('Distribution after spectral clustering using Unnormalized Laplacian Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-12\n",
    "\n",
    "# Count eigenvalues close to zero\n",
    "zero_eigenvalues = np.sum(np.abs(eigenvals) < epsilon)\n",
    "print(f\"Number of zero eigenvalues: {zero_eigenvalues}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_inv_sqrt_2 = np.diag(1.0 / np.sqrt(np.diag(degree_matrix_2)))\n",
    "\n",
    "normalized_L_2 = D_inv_sqrt_2@unnorm_laplacian_matrix_2@D_inv_sqrt_2\n",
    "np.isinf(D_inv_sqrt_2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(normalized_L_2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_eigenvals_2, norm_eigenvects_2 = eigenspace_calculation(matrix=normalized_L_2, k=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_eigenvector_1=norm_eigenvects_2[:,1]\n",
    "norm_eigenvector_2=norm_eigenvects_2[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_two_eig_df_2 = pd.DataFrame(np.column_stack((norm_eigenvector_1, norm_eigenvector_2)), columns=['eigenvect1', 'eigenvect2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x=norm_two_eig_df_2['eigenvect1'], y=norm_two_eig_df_2['eigenvect2'], marker='o', alpha=0.9, c=norm_two_eig_df_2['eigenvect1'], cmap='viridis', s=10)\n",
    "plt.xlabel('Eigenvector 2')\n",
    "plt.ylabel('Eigenvector 3')\n",
    "plt.title('Distribution  of swiss roll after spectral clustering using Normalized Laplacian Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
